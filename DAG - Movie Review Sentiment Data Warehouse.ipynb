{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG - Movie Review Sentiment Data Warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The present documents lays out the Data Pipeline of how the Sentiment Analysis DAG should be performed by the DAG. Once we are certain about the algorithm, the code explored here must be transformed in a DAG and deployed to Airflow, so that it can be scheduled to perform the backfill and the continuous processing accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:53:29.553388Z",
     "start_time": "2020-08-10T21:53:03.943763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\r\n",
      "\r\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\r\n",
      "\r\n",
      "awscli 1.18.69 requires botocore==1.16.19, but you'll have botocore 1.17.39 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U requests\n",
    "!pip install -q -U boto3\n",
    "!pip install -q -U ipython-sql\n",
    "!pip install -q -U psycopg2-binary\n",
    "!pip install -q -U tensorflow\n",
    "!pip install -q -U matplotlib\n",
    "!pip install -q -U reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:53:38.710766Z",
     "start_time": "2020-08-10T21:53:29.563162Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import zipfile\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import time\n",
    "import psycopg2\n",
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlparse\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redshift Connection Url\n",
    "\n",
    "**Note:** Copy this URL is generated in the main notebook, generated during the Redshift installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:53:38.727142Z",
     "start_time": "2020-08-10T21:53:38.713835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'postgresql://redshift:r4d$hifT@35.178.10.130:5439/dw_movie_review_sentiment'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redshift_url = 'postgresql://redshift:r4d$hifT@35.178.10.130:5439/dw_movie_review_sentiment'\n",
    "redshift_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redshift Copy Role\n",
    "\n",
    "**Note:** Copy this URL is generated in the main notebook, generated during the Redshift installation.\n",
    "\n",
    "Redshift must have a *service role*, with *read only access to S3* in order to perform the copy operation. Please insert here the name of your role that shall be used by the **`COPY`** command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:53:38.738892Z",
     "start_time": "2020-08-10T21:53:38.729889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::673962978035:role/hudsonmendes-dw-movie-sentiment-analysis-role'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iam_role = 'arn:aws:iam::673962978035:role/hudsonmendes-dw-movie-sentiment-analysis-role'\n",
    "iam_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Staging Bucket\n",
    "\n",
    "**Redshift** does not read from zip packages. Even though it can **S3** folders and can collect files found in them, the files need to be individually placed in uncompressed format, or individually compressed (e.g.: _GZIP_ format). \n",
    "\n",
    "Please use the section bellow to determine the name of the bucket that you will use as your staging for the files that will later be injested by Redshift into the staging tables.\n",
    "\n",
    "**Important:** bucket names are unique for AWS and you must choose one you have write access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:53:38.758582Z",
     "start_time": "2020-08-10T21:53:38.753679Z"
    }
   },
   "outputs": [],
   "source": [
    "staging_bucket = 'hudsonmendes-dw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs and Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies Source And Staging Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:53:38.773148Z",
     "start_time": "2020-08-10T21:53:38.763391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://hudsonmendes-datalake.s3.eu-west-2.amazonaws.com/kaggle/hudsonmendes/tmdb-movies-with-imdb_id.zip',\n",
       " 'tmdb-movies-with-imdb_id/')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmdb_movies_source_url  = 'https://hudsonmendes-datalake.s3.eu-west-2.amazonaws.com/kaggle/hudsonmendes/tmdb-movies-with-imdb_id.zip'\n",
    "tmdb_movies_staging_folder = f'tmdb-movies-with-imdb_id/'\n",
    "(tmdb_movies_source_url, tmdb_movies_staging_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews Source and Staging Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:53:38.784983Z",
     "start_time": "2020-08-10T21:53:38.778595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://hudsonmendes-datalake.s3.eu-west-2.amazonaws.com/kaggle/hudsonmendes/tmdb-reviews.zip',\n",
       " 'tmdb-reviews')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmdb_reviews_source_url  = 'https://hudsonmendes-datalake.s3.eu-west-2.amazonaws.com/kaggle/hudsonmendes/tmdb-reviews.zip'\n",
    "tmdb_reviews_staging_folder = f'tmdb-reviews'\n",
    "(tmdb_reviews_source_url, tmdb_reviews_staging_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDb Cast (Links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:53:38.794770Z",
     "start_time": "2020-08-10T21:53:38.789813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://datasets.imdbws.com/title.principals.tsv.gz',\n",
       " 'imdb-cast/imdb-cast-1597096418.tsv.gz')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_cast_source_url = 'https://datasets.imdbws.com/title.principals.tsv.gz'\n",
    "imdb_cast_staging_path = f'imdb-cast/imdb-cast-{int(time.time())}.tsv.gz'\n",
    "(imdb_cast_source_url, imdb_cast_staging_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDb Cast (Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:53:38.805175Z",
     "start_time": "2020-08-10T21:53:38.798337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://datasets.imdbws.com/name.basics.tsv.gz',\n",
       " 'imdb-cast/imdb-cast-names1597096418.tsv.gz')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_names_source_url = 'https://datasets.imdbws.com/name.basics.tsv.gz'\n",
    "imdb_names_staging_path = f'imdb-cast/imdb-cast-names{int(time.time())}.tsv.gz'\n",
    "(imdb_names_source_url, imdb_names_staging_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "This Pipeline is composed by the following steps:\n",
    "\n",
    "1. Unzip files from the **Data Lake** into our **Staging S3**\n",
    "2. **`COPY`** data from **Staging S3** to out **Redshift Staging Tables**\n",
    "3. _Extract, Transform and Load_ the data into our **Data Warehouse Dimensions Table**\n",
    "4. **Classify Sentiment** of Movie Reviews using our Model, generating our **Data Warehouse Facts Table**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files within ZIP to S3 Staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:53:38.816654Z",
     "start_time": "2020-08-10T21:53:38.808221Z"
    }
   },
   "outputs": [],
   "source": [
    "def stage_zip_files_to_s3(\n",
    "        source_url,\n",
    "        destination_bucket,\n",
    "        destination_folder):\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    print(f'Downloading \"{source_url}\", please wait...')\n",
    "    with urlopen(source_url) as res:\n",
    "        buffer = io.BytesIO(res.read())\n",
    "        file_zip = zipfile.ZipFile(buffer)\n",
    "        print('Download completed.')\n",
    "\n",
    "        print(f'Uploading each file in \"{source_url}\" to s3://{destination_bucket}/{destination_folder}')\n",
    "        for inner_file_name in tqdm(file_zip.namelist(), 'extracting to s3'):\n",
    "            inner_file_buffer = file_zip.read(inner_file_name) \n",
    "            s3.put_object(\n",
    "                Bucket=staging_bucket,\n",
    "                Key=os.path.join(destination_folder, inner_file_name),\n",
    "                Body=inner_file_buffer)\n",
    "            print(f'[ok] {inner_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:54:10.510604Z",
     "start_time": "2020-08-10T21:53:38.819267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading \"https://hudsonmendes-datalake.s3.eu-west-2.amazonaws.com/kaggle/hudsonmendes/tmdb-movies-with-imdb_id.zip\", please wait...\n",
      "Download completed.\n",
      "Uploading each file in \"https://hudsonmendes-datalake.s3.eu-west-2.amazonaws.com/kaggle/hudsonmendes/tmdb-movies-with-imdb_id.zip\" to s3://hudsonmendes-dw/tmdb-movies-with-imdb_id/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc7519ffd2a4826a0265a42eb181e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='extracting to s3', max=21.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] tmdb-movies-2000.json\n",
      "[ok] tmdb-movies-2001.json\n",
      "[ok] tmdb-movies-2002.json\n",
      "[ok] tmdb-movies-2003.json\n",
      "[ok] tmdb-movies-2004.json\n",
      "[ok] tmdb-movies-2005.json\n",
      "[ok] tmdb-movies-2006.json\n",
      "[ok] tmdb-movies-2007.json\n",
      "[ok] tmdb-movies-2008.json\n",
      "[ok] tmdb-movies-2009.json\n",
      "[ok] tmdb-movies-2010.json\n",
      "[ok] tmdb-movies-2011.json\n",
      "[ok] tmdb-movies-2012.json\n",
      "[ok] tmdb-movies-2013.json\n",
      "[ok] tmdb-movies-2014.json\n",
      "[ok] tmdb-movies-2015.json\n",
      "[ok] tmdb-movies-2016.json\n",
      "[ok] tmdb-movies-2017.json\n",
      "[ok] tmdb-movies-2018.json\n",
      "[ok] tmdb-movies-2019.json\n",
      "[ok] tmdb-movies-2020.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stage_zip_files_to_s3(\n",
    "    source_url=tmdb_movies_source_url,\n",
    "    destination_bucket=staging_bucket,\n",
    "    destination_folder=tmdb_movies_staging_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:54:18.701195Z",
     "start_time": "2020-08-10T21:54:10.519932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading \"https://hudsonmendes-datalake.s3.eu-west-2.amazonaws.com/kaggle/hudsonmendes/tmdb-reviews.zip\", please wait...\n",
      "Download completed.\n",
      "Uploading each file in \"https://hudsonmendes-datalake.s3.eu-west-2.amazonaws.com/kaggle/hudsonmendes/tmdb-reviews.zip\" to s3://hudsonmendes-dw/tmdb-reviews\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f551b6f52c534a7c9279067448d92dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='extracting to s3', max=21.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] tmdb-movies-2000-reviews.json\n",
      "[ok] tmdb-movies-2001-reviews.json\n",
      "[ok] tmdb-movies-2002-reviews.json\n",
      "[ok] tmdb-movies-2003-reviews.json\n",
      "[ok] tmdb-movies-2004-reviews.json\n",
      "[ok] tmdb-movies-2005-reviews.json\n",
      "[ok] tmdb-movies-2006-reviews.json\n",
      "[ok] tmdb-movies-2007-reviews.json\n",
      "[ok] tmdb-movies-2008-reviews.json\n",
      "[ok] tmdb-movies-2009-reviews.json\n",
      "[ok] tmdb-movies-2010-reviews.json\n",
      "[ok] tmdb-movies-2011-reviews.json\n",
      "[ok] tmdb-movies-2012-reviews.json\n",
      "[ok] tmdb-movies-2013-reviews.json\n",
      "[ok] tmdb-movies-2014-reviews.json\n",
      "[ok] tmdb-movies-2015-reviews.json\n",
      "[ok] tmdb-movies-2016-reviews.json\n",
      "[ok] tmdb-movies-2017-reviews.json\n",
      "[ok] tmdb-movies-2018-reviews.json\n",
      "[ok] tmdb-movies-2019-reviews.json\n",
      "[ok] tmdb-movies-2020-reviews.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stage_zip_files_to_s3(\n",
    "    source_url=tmdb_reviews_source_url,\n",
    "    destination_bucket=staging_bucket,\n",
    "    destination_folder=tmdb_reviews_staging_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload `.tsv.gz`  to S3 Staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:54:18.723919Z",
     "start_time": "2020-08-10T21:54:18.706373Z"
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================================\n",
    "# Source: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-uploading-files.html\n",
    "# =============================================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "class ProgressPercentage(object):\n",
    "\n",
    "    def __init__(self, buffer):\n",
    "        self.buffer = buffer\n",
    "        self._size = sys.getsizeof(buffer)\n",
    "        self.pbar = tqdm(total=self._size, unit='B', unit_scale=True, desc='uploading')\n",
    "        self._lock = threading.Lock()\n",
    "\n",
    "    def __call__(self, bytes_amount):\n",
    "        with self._lock:\n",
    "            self.pbar.update(bytes_amount)\n",
    "            \n",
    "    def close(self):\n",
    "        self.pbar.update(self._size - self.pbar.n)\n",
    "        self.pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:54:18.740044Z",
     "start_time": "2020-08-10T21:54:18.727279Z"
    }
   },
   "outputs": [],
   "source": [
    "def stage_file_to_s3(\n",
    "        source_url,\n",
    "        destination_bucket,\n",
    "        destination_path):\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "    file_name = os.path.basename(source_url)\n",
    "    file_size = int(urlopen(source_url).info().get('Content-Length', -1))\n",
    "    pbar = tqdm(total=file_size, unit='B', unit_scale=True, desc='downloading')\n",
    "    req = requests.get(source_url, stream=True)\n",
    "    buffer = io.BytesIO()\n",
    "    for chunk in req.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            buffer.write(chunk)\n",
    "            pbar.update(1024)\n",
    "    pbar.close()\n",
    "    \n",
    "    pbar = ProgressPercentage(buffer)\n",
    "    buffer.seek(0)\n",
    "    s3.upload_fileobj(\n",
    "        Fileobj=buffer,\n",
    "        Bucket=staging_bucket,\n",
    "        Key=destination_path,\n",
    "        Callback=pbar)\n",
    "    pbar.close()\n",
    "    print(f'[ok] {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:56:44.438251Z",
     "start_time": "2020-08-10T21:54:18.743398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e22e8cebd24fd8b27ccff91b3dabdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='downloading', max=331029653.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20da4c98919c471593421f91aa59925b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='uploading', max=342837631.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ok] title.principals.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "stage_file_to_s3(\n",
    "    source_url=imdb_cast_source_url,\n",
    "    destination_bucket=staging_bucket,\n",
    "    destination_path=imdb_cast_staging_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:58:14.116213Z",
     "start_time": "2020-08-10T21:56:44.441982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b36d3308af7479ab30cf9a823149694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='downloading', max=200576057.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7f5b8ebaa4434d940efe7f3579d350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='uploading', max=214031359.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ok] name.basics.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "stage_file_to_s3(\n",
    "    source_url=imdb_names_source_url,\n",
    "    destination_bucket=staging_bucket,\n",
    "    destination_path=imdb_names_staging_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From S3 Staging to Reshift Staging Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:58:14.657959Z",
     "start_time": "2020-08-10T21:58:14.120086Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:30.990486Z",
     "start_time": "2020-08-10T21:58:14.660468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(psycopg2.OperationalError) could not connect to server: Operation timed out\n",
      "\tIs the server running on host \"35.178.10.130\" and accepting\n",
      "\tTCP/IP connections on port 5439?\n",
      "\n",
      "(Background on this error at: http://sqlalche.me/e/13/e3q8)\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%sql $redshift_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDb Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.002619Z",
     "start_time": "2020-08-10T21:59:30.995931Z"
    }
   },
   "outputs": [],
   "source": [
    "tmdb_movies_staging_url = f's3://{staging_bucket}/{tmdb_movies_staging_folder}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.019234Z",
     "start_time": "2020-08-10T21:59:31.005931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "drop table if exists staging_tmdb_movies;\n",
    "\n",
    "create table staging_tmdb_movies (\n",
    "    id                integer,\n",
    "    video             boolean,\n",
    "    vote_count        bigint,\n",
    "    vote_average      numeric(10, 6),\n",
    "    title             varchar(256),\n",
    "    release_date      timestamp,\n",
    "    original_language varchar(10), \n",
    "    original_title    varchar(256),\n",
    "    genre_ids         varchar(1024),\n",
    "    backdrop_path     varchar(1024),\n",
    "    adult             boolean,\n",
    "    overview          varchar(10000),\n",
    "    poster_path       varchar(1024),\n",
    "    popularity        numeric(10, 6),\n",
    "    id_imdb           varchar(32)\n",
    ");\n",
    "\n",
    "copy public.staging_tmdb_movies\n",
    "from :tmdb_movies_staging_url\n",
    "iam_role :iam_role\n",
    "region 'eu-west-2'\n",
    "format as json 'auto';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDb Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.029472Z",
     "start_time": "2020-08-10T21:59:31.023534Z"
    }
   },
   "outputs": [],
   "source": [
    "tmdb_reviews_staging_url = f's3://{staging_bucket}/{tmdb_reviews_staging_folder}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.046589Z",
     "start_time": "2020-08-10T21:59:31.040513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "drop table if exists staging_tmdb_reviews;\n",
    "\n",
    "create table staging_tmdb_reviews (\n",
    "    author   varchar(256),\n",
    "    content  varchar(40000),\n",
    "    id       varchar(40),\n",
    "    url      varchar(256),\n",
    "    movie_id integer\n",
    ");\n",
    "\n",
    "copy public.staging_tmdb_reviews\n",
    "from :tmdb_reviews_staging_url\n",
    "iam_role :iam_role\n",
    "region 'eu-west-2'\n",
    "format as json 'auto';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDb Cast (Links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.059450Z",
     "start_time": "2020-08-10T21:59:31.054066Z"
    }
   },
   "outputs": [],
   "source": [
    "imdb_cast_staging_url = f's3://{staging_bucket}/{imdb_cast_staging_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.069693Z",
     "start_time": "2020-08-10T21:59:31.062742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "drop table if exists staging_imdb_cast;\n",
    "\n",
    "create table staging_imdb_cast (\n",
    "    tconst     varchar(40),\n",
    "    ordering   varchar(10),\n",
    "    nconst     varchar(40),\n",
    "    category   varchar(256),\n",
    "    job        varchar(1024),\n",
    "    characters varchar(1024)\n",
    ");\n",
    "\n",
    "copy public.staging_imdb_cast\n",
    "from :imdb_cast_staging_url\n",
    "iam_role :iam_role\n",
    "region 'eu-west-2'\n",
    "delimiter '\\t'\n",
    "gzip;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDb Cast (Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.081314Z",
     "start_time": "2020-08-10T21:59:31.075658Z"
    }
   },
   "outputs": [],
   "source": [
    "imdb_names_staging_url = f's3://{staging_bucket}/{imdb_names_staging_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.091851Z",
     "start_time": "2020-08-10T21:59:31.084601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "drop table if exists staging_imdb_names;\n",
    "\n",
    "create table staging_imdb_names (\n",
    "    nconst            varchar(40),\n",
    "    primaryname       varchar(256),\n",
    "    birthyear         varchar(10),\n",
    "    deathyear         varchar(10),\n",
    "    primaryprofession varchar(256),\n",
    "    knownfortitles    varchar(256)\n",
    ");\n",
    "\n",
    "copy public.staging_imdb_names\n",
    "from :imdb_names_staging_url\n",
    "iam_role :iam_role\n",
    "region 'eu-west-2'\n",
    "delimiter '\\t'\n",
    "gzip;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Redshift Staging to Dimension Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `dim_dates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.102462Z",
     "start_time": "2020-08-10T21:59:31.095204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "truncate table dim_dates;\n",
    "\n",
    "insert into dim_dates\n",
    "select release_date as date_id,\n",
    "       datepart(year, release_date)  as year,\n",
    "       datepart(month, release_date) as month,\n",
    "       datepart(day, release_date)   as day\n",
    "from (\n",
    "    select distinct release_date\n",
    "    from staging_tmdb_movies\n",
    "    where not release_date is null);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `dim_films`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.113200Z",
     "start_time": "2020-08-10T21:59:31.106003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "truncate table dim_films;\n",
    "\n",
    "insert into dim_films (film_id, date_id, title)\n",
    "select id, release_date, title\n",
    "from staging_tmdb_movies\n",
    "where not release_date is null;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `dim_cast`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.124040Z",
     "start_time": "2020-08-10T21:59:31.116639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "truncate table dim_cast;\n",
    "\n",
    "insert into dim_cast (cast_id, film_id, full_name)\n",
    "select imdbc.nconst, tmdbm.id, imdbn.primaryname\n",
    "from staging_imdb_cast as imdbc\n",
    "  inner join staging_imdb_names as imdbn on imdbc.nconst = imdbn.nconst\n",
    "  inner join staging_tmdb_movies as tmdbm on tmdbm.id_imdb = imdbc.tconst\n",
    "where not release_date is null\n",
    "  and imdbc.category in ('actor', 'actress');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `dim_reviews`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.134278Z",
     "start_time": "2020-08-10T21:59:31.127215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "truncate table dim_reviews;\n",
    "\n",
    "insert into dim_reviews (review_id, film_id, text)\n",
    "select id, movie_id, content\n",
    "from staging_tmdb_reviews;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facts Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.146868Z",
     "start_time": "2020-08-10T21:59:31.138381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "truncate table fact_film_review_sentiments;\n",
    "\n",
    "insert into fact_film_review_sentiments (\n",
    "    date_id,\n",
    "    film_id,\n",
    "    review_id,\n",
    "    review_sentiment_class)\n",
    "select df.date_id, df.film_id, dr.review_id, 0\n",
    "from dim_films as df\n",
    "    inner join dim_reviews as dr on df.film_id = dr.film_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:31.157568Z",
     "start_time": "2020-08-10T21:59:31.150474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "truncate table fact_cast_review_sentiments;\n",
    "\n",
    "insert into fact_cast_review_sentiments (\n",
    "    date_id,\n",
    "    cast_id,\n",
    "    review_id,\n",
    "    review_sentiment_class)\n",
    "select df.date_id, dc.cast_id, dr.review_id, 0\n",
    "from dim_cast as dc\n",
    "    inner join dim_films as df on dc.film_id = df.film_id\n",
    "    inner join dim_reviews as dr on dc.film_id = dr.film_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:32.755257Z",
     "start_time": "2020-08-10T21:59:31.160866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x13c405b70>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.saved_model.load('./model/movie-sentiment-classifier')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:59:33.555409Z",
     "start_time": "2020-08-10T21:59:32.760041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x13d3fcba8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "tokenizer = None\n",
    "with open('./model/movie-sentiment-classifier/assets/tokenizer.json', 'r', encoding='utf-8') as tokenizer_file:\n",
    "    tokenizer_json = json.dumps(json.load(tokenizer_file))\n",
    "    tokenizer = keras.preprocessing.text.tokenizer_from_json(tokenizer_json)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.814259Z",
     "start_time": "2020-08-10T21:59:33.558055Z"
    }
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not connect to server: Operation timed out\n\tIs the server running on host \"35.178.10.130\" and accepting\n\tTCP/IP connections on port 5439?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-509e71c0d5a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredshift_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/psycopg2/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: could not connect to server: Operation timed out\n\tIs the server running on host \"35.178.10.130\" and accepting\n\tTCP/IP connections on port 5439?\n"
     ]
    }
   ],
   "source": [
    "db = psycopg2.connect(redshift_url)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.819236Z",
     "start_time": "2020-08-10T21:53:04.115Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "cur = db.cursor()\n",
    "cur.execute('select review_id, text from dim_reviews')\n",
    "for review_id, text in tqdm(cur.fetchall(), desc='reviews'):\n",
    "    reviews.append({'review_id': review_id, 'text': text })\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.821293Z",
     "start_time": "2020-08-10T21:53:04.130Z"
    }
   },
   "outputs": [],
   "source": [
    "review_texts = [ r['text'] for r in reviews ]\n",
    "review_seqs  = tokenizer.texts_to_sequences(review_texts)\n",
    "review_seqs  = tf.keras.preprocessing.sequence.pad_sequences(review_seqs, maxlen=500, dtype='float32', padding='post', value=0)\n",
    "(len(reviews), len(review_texts), review_seqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.823293Z",
     "start_time": "2020-08-10T21:53:04.135Z"
    }
   },
   "outputs": [],
   "source": [
    "review_preds = model(inputs=review_seqs)\n",
    "len(review_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.825396Z",
     "start_time": "2020-08-10T21:53:04.142Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_review_sentiment_class_for(table):\n",
    "    cur = db.cursor()\n",
    "    try:\n",
    "        sql = f\"\"\"update {table}\n",
    "                 set review_sentiment_class = %s\n",
    "                 where review_id = %s\"\"\"\n",
    "        batch = []\n",
    "        pbar = tqdm(enumerate(review_preds), total=len(review_preds), desc=table)\n",
    "        for i, review_pred in pbar:\n",
    "            review_id = reviews[i]['review_id']\n",
    "            review_sentiment = -1 if np.argmax(review_preds[i]) else 1\n",
    "            batch.append((review_sentiment, review_id))\n",
    "            if len(batch) % 200 == 0:\n",
    "                cur.executemany(sql, batch)\n",
    "                db.commit()\n",
    "                batch.clear()\n",
    "                pbar.refresh()\n",
    "        if len(batch) > 0:\n",
    "            cur.executemany(sql, batch)\n",
    "            db.commit()\n",
    "            batch.clear()\n",
    "            pbar.refresh()\n",
    "        pbar.close()\n",
    "        cur.close()\n",
    "    except Exception as e:\n",
    "        db.rollback()\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.828364Z",
     "start_time": "2020-08-10T21:53:04.147Z"
    }
   },
   "outputs": [],
   "source": [
    "update_review_sentiment_class_for('fact_film_review_sentiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.831417Z",
     "start_time": "2020-08-10T21:53:04.151Z"
    }
   },
   "outputs": [],
   "source": [
    "update_review_sentiment_class_for('fact_cast_review_sentiments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.834675Z",
     "start_time": "2020-08-10T21:53:04.157Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql dates_source_count <<\n",
    "select count(distinct release_date)\n",
    "from staging_tmdb_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.839110Z",
     "start_time": "2020-08-10T21:53:04.162Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql dates_dest_count <<\n",
    "select count(date_id)\n",
    "from dim_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.842770Z",
     "start_time": "2020-08-10T21:53:04.166Z"
    }
   },
   "outputs": [],
   "source": [
    "print((dates_source_count[0][0], dates_dest_count[0][0]))\n",
    "assert dates_source_count == dates_dest_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.846197Z",
     "start_time": "2020-08-10T21:53:04.170Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql films_source_count <<\n",
    "select count(id_imdb)\n",
    "from staging_tmdb_movies\n",
    "where not release_date is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.848988Z",
     "start_time": "2020-08-10T21:53:04.174Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql films_dest_count <<\n",
    "select count(film_id)\n",
    "from dim_films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.851430Z",
     "start_time": "2020-08-10T21:53:04.178Z"
    }
   },
   "outputs": [],
   "source": [
    "print((films_source_count[0][0], films_dest_count[0][0]))\n",
    "assert films_source_count == films_dest_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.854911Z",
     "start_time": "2020-08-10T21:53:04.182Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql reviews_source_count <<\n",
    "select count(id)\n",
    "from staging_tmdb_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.857402Z",
     "start_time": "2020-08-10T21:53:04.186Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql reviews_dest_count <<\n",
    "select count(review_id)\n",
    "from dim_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.866280Z",
     "start_time": "2020-08-10T21:53:04.191Z"
    }
   },
   "outputs": [],
   "source": [
    "print((reviews_source_count[0][0], reviews_dest_count[0][0]))\n",
    "assert reviews_source_count == reviews_dest_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.869672Z",
     "start_time": "2020-08-10T21:53:04.196Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql cast_source_count <<\n",
    "select count(imdbc.nconst)\n",
    "from staging_imdb_cast as imdbc\n",
    "  inner join staging_tmdb_movies as tmdbm on imdbc.tconst = tmdbm.id_imdb\n",
    "  inner join staging_imdb_names as imdbn on imdbc.nconst = imdbn.nconst\n",
    "where not release_date is null\n",
    "  and imdbc.category in ('actor', 'actress');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.873997Z",
     "start_time": "2020-08-10T21:53:04.199Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql cast_dest_count <<\n",
    "select count(cast_id)\n",
    "from dim_cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.877449Z",
     "start_time": "2020-08-10T21:53:04.203Z"
    }
   },
   "outputs": [],
   "source": [
    "print((cast_source_count[0][0], cast_dest_count[0][0]))\n",
    "assert cast_source_count == cast_dest_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Film Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.880451Z",
     "start_time": "2020-08-10T21:53:04.209Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql film_fact_source_count <<\n",
    "select count(0)\n",
    "from dim_films as df\n",
    "    inner join dim_reviews as dr on df.film_id = dr.film_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.883948Z",
     "start_time": "2020-08-10T21:53:04.213Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql film_fact_dest_count <<\n",
    "select count(0)\n",
    "from fact_film_review_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.888049Z",
     "start_time": "2020-08-10T21:53:04.217Z"
    }
   },
   "outputs": [],
   "source": [
    "print((film_fact_source_count[0][0], film_fact_dest_count[0][0]))\n",
    "assert film_fact_source_count == film_fact_dest_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cast Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.890689Z",
     "start_time": "2020-08-10T21:53:04.222Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql cast_fact_source_count <<\n",
    "select count(0)\n",
    "from dim_cast as dc\n",
    "    inner join dim_reviews as dr on dc.film_id = dr.film_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.893457Z",
     "start_time": "2020-08-10T21:53:04.233Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql cast_fact_dest_count <<\n",
    "select count(0)\n",
    "from fact_cast_review_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.895855Z",
     "start_time": "2020-08-10T21:53:04.236Z"
    }
   },
   "outputs": [],
   "source": [
    "print((cast_fact_source_count[0][0], cast_fact_dest_count[0][0]))\n",
    "assert cast_fact_source_count == cast_fact_dest_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Existence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Films in Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.898900Z",
     "start_time": "2020-08-10T21:53:04.242Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql films_not_in_facts <<\n",
    "select df.film_id\n",
    "from dim_films as df\n",
    "  inner join dim_reviews as dr on df.film_id = dr.film_id\n",
    "where df.film_id not in (select f.film_id from fact_film_review_sentiments as f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.901681Z",
     "start_time": "2020-08-10T21:53:04.246Z"
    }
   },
   "outputs": [],
   "source": [
    "assert not films_not_in_facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reviews in Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.905344Z",
     "start_time": "2020-08-10T21:53:04.251Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql reviews_not_in_facts <<\n",
    "select dr.review_id\n",
    "from dim_reviews as dr\n",
    "where dr.review_id not in (select f.review_id from fact_film_review_sentiments as f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.908991Z",
     "start_time": "2020-08-10T21:53:04.254Z"
    }
   },
   "outputs": [],
   "source": [
    "assert not reviews_not_in_facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cast in Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.912086Z",
     "start_time": "2020-08-10T21:53:04.259Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql cast_not_in_facts <<\n",
    "select dc.cast_id\n",
    "from dim_cast as dc\n",
    "  inner join dim_reviews as dr on dc.film_id = dr.film_id\n",
    "where dc.cast_id not in (select f.cast_id from fact_cast_review_sentiments as f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.915246Z",
     "start_time": "2020-08-10T21:53:04.263Z"
    }
   },
   "outputs": [],
   "source": [
    "assert not cast_not_in_facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentiment Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.917510Z",
     "start_time": "2020-08-10T21:53:04.268Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql sentiment_classes <<\n",
    "select distinct review_sentiment_class\n",
    "from fact_film_review_sentiments\n",
    "union\n",
    "select distinct review_sentiment_class\n",
    "from fact_cast_review_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.920090Z",
     "start_time": "2020-08-10T21:53:04.272Z"
    }
   },
   "outputs": [],
   "source": [
    "print(set([ x[0] for x in sentiment_classes ]))\n",
    "assert set([ x[0] for x in sentiment_classes ]) == set([-1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.924130Z",
     "start_time": "2020-08-10T21:53:04.278Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select df.title, sum(f.review_sentiment_class) as sentiment\n",
    "from fact_film_review_sentiments as f\n",
    "  inner join dim_films as df on f.film_id = df.film_id\n",
    "  inner join dim_reviews as dr on f.review_id = dr.review_id\n",
    "group by df.title\n",
    "order by sentiment desc\n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Worst Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.927662Z",
     "start_time": "2020-08-10T21:53:04.285Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select df.title, sum(f.review_sentiment_class) as sentiment\n",
    "from fact_film_review_sentiments as f\n",
    "  inner join dim_films as df on f.film_id = df.film_id\n",
    "  inner join dim_reviews as dr on f.review_id = dr.review_id\n",
    "group by df.title\n",
    "order by sentiment asc\n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Actors in Films with Best Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.930346Z",
     "start_time": "2020-08-10T21:53:04.290Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select dc.full_name, sum(f.review_sentiment_class) as sentiment\n",
    "from fact_cast_review_sentiments as f\n",
    "  inner join dim_cast as dc on f.cast_id = dc.cast_id\n",
    "  inner join dim_reviews as dr on f.review_id = dr.review_id\n",
    "group by dc.full_name\n",
    "order by sentiment desc\n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.932787Z",
     "start_time": "2020-08-10T21:53:04.296Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select dt.year, sum(f.review_sentiment_class) as sentiment\n",
    "from fact_film_review_sentiments as f\n",
    "    inner join dim_dates as dt on f.date_id = dt.date_id\n",
    "group by dt.year\n",
    "order by dt.year asc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.935741Z",
     "start_time": "2020-08-10T21:53:04.301Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_scale = 2.5\n",
    "def sentiment_normalizer(max_sentiment):\n",
    "    return lambda x: round(sentiment_scale + (sentiment_scale * x / max_sentiment), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Per Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.939783Z",
     "start_time": "2020-08-10T21:53:04.306Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql film_sentiments <<\n",
    "select df.title, sum(f.review_sentiment_class) as sentiment\n",
    "from fact_film_review_sentiments as f\n",
    "  inner join dim_films as df on f.film_id = df.film_id\n",
    "group by df.title\n",
    "order by sentiment desc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.943586Z",
     "start_time": "2020-08-10T21:53:04.310Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_films = pd.DataFrame(film_sentiments, columns=['title', 'sentiment'])\n",
    "df_films = df_films.set_index('title')\n",
    "df_films.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.951541Z",
     "start_time": "2020-08-10T21:53:04.316Z"
    }
   },
   "outputs": [],
   "source": [
    "df_films_normalizer = sentiment_normalizer(max(df_films.sentiment))\n",
    "df_films['normalized_sentiment'] = df_films['sentiment'].map(df_films_normalizer)\n",
    "df_films.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Per Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.955814Z",
     "start_time": "2020-08-10T21:53:04.321Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql cast_sentiments <<\n",
    "select dc.full_name, sum(f.review_sentiment_class) as sentiment\n",
    "from fact_cast_review_sentiments f\n",
    "  inner join dim_cast as dc on f.cast_id = dc.cast_id\n",
    "group by dc.full_name\n",
    "order by sentiment desc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.959471Z",
     "start_time": "2020-08-10T21:53:04.325Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cast = pd.DataFrame(cast_sentiments, columns=['full_name', 'sentiment'])\n",
    "df_cast = df_cast.set_index('full_name')\n",
    "df_cast_normalizer = sentiment_normalizer(max(df_cast.sentiment))\n",
    "df_cast['normalized_sentiment'] = df_cast['sentiment'].map(df_cast_normalizer)\n",
    "df_cast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.963492Z",
     "start_time": "2020-08-10T21:53:04.331Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql year_sentiments <<\n",
    "select dt.year, sum(f.review_sentiment_class) as sentiment\n",
    "from fact_film_review_sentiments as f\n",
    "    inner join dim_dates as dt on f.date_id = dt.date_id\n",
    "group by dt.year\n",
    "order by dt.year asc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.966149Z",
     "start_time": "2020-08-10T21:53:04.337Z"
    }
   },
   "outputs": [],
   "source": [
    "df_year = pd.DataFrame(year_sentiments, columns=['year', 'sentiment'])\n",
    "df_year = df_year.set_index('year')\n",
    "df_year.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publishing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.969302Z",
     "start_time": "2020-08-10T21:53:04.343Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.971777Z",
     "start_time": "2020-08-10T21:53:04.348Z"
    }
   },
   "outputs": [],
   "source": [
    "year  = str(datetime.now().year).rjust(4, '0')\n",
    "month = str(datetime.now().month).rjust(2, '0')\n",
    "day   = str(datetime.now().day).rjust(2, '0')\n",
    "title = f'TMDb, Film Review Sentiment Analysis ({year}-{month}-{day})'\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart: Review Distribution per Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.975117Z",
     "start_time": "2020-08-10T21:53:04.356Z"
    }
   },
   "outputs": [],
   "source": [
    "film_review_distro_path = './images/film_review_distro_fig.png'\n",
    "film_review_distro_fig = df_films[['sentiment']] \\\n",
    "    .plot \\\n",
    "    .density(bw_method=1, grid=True, figsize=(7, 3)) \\\n",
    "    .get_figure()\n",
    "film_review_distro_fig.savefig(film_review_distro_path, format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart: Sentiment over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.978560Z",
     "start_time": "2020-08-10T21:53:04.361Z"
    }
   },
   "outputs": [],
   "source": [
    "year_review_distro_path = './images/year_review_distro_fig.png'\n",
    "year_review_distro_fig = df_year \\\n",
    "    .plot \\\n",
    "    .bar(grid=True, figsize=(7, 4)) \\\n",
    "    .get_figure()\n",
    "year_review_distro_fig.savefig(year_review_distro_path, format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: Top 10 Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.981820Z",
     "start_time": "2020-08-10T21:53:04.367Z"
    }
   },
   "outputs": [],
   "source": [
    "top_10_films= df_films[['normalized_sentiment']].head(10)\n",
    "top_10_films"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: Worst 10 Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.984594Z",
     "start_time": "2020-08-10T21:53:04.373Z"
    }
   },
   "outputs": [],
   "source": [
    "worst_10_films= df_films[['normalized_sentiment']] \\\n",
    "    .tail(10) \\\n",
    "    .sort_values(by='normalized_sentiment', ascending=True)\n",
    "worst_10_films"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: Top 10 Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.987261Z",
     "start_time": "2020-08-10T21:53:04.379Z"
    }
   },
   "outputs": [],
   "source": [
    "top_10_cast = df_cast[['normalized_sentiment']].head(10)\n",
    "top_10_cast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T22:00:49.992101Z",
     "start_time": "2020-08-10T21:53:04.384Z"
    }
   },
   "outputs": [],
   "source": [
    "from reportlab.lib.units import cm\n",
    "from reportlab.lib.utils import ImageReader\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Image, Table, TableStyle, Spacer, PageBreak\n",
    "from reportlab.lib.colors import black\n",
    "\n",
    "doc = SimpleDocTemplate('report.pdf', pagesize=A4, rightMargin=cm, leftMargin=cm, topMargin=cm, bottomMargin=cm)\n",
    "doc.title = title\n",
    "width, height = A4\n",
    "\n",
    "style_title = getSampleStyleSheet()[\"title\"]\n",
    "style_h1 = getSampleStyleSheet()[\"h1\"]\n",
    "style_normal = getSampleStyleSheet()[\"bu\"]\n",
    "style_grid = TableStyle([\n",
    "    ('GRID', (0, 0), (-1, -1), 1, black),\n",
    "    ('ALIGN', (1, 0), (-1, -1), 'RIGHT')])\n",
    "\n",
    "br = Spacer(width, 20)\n",
    "\n",
    "elements = []\n",
    "elements.append(Paragraph(title, style=style_title))\n",
    "elements.append(Image('./images/header.png', width-(2*cm), 220))\n",
    "elements.append(br)\n",
    "\n",
    "elements.append(Paragraph('Executive Summary', style=style_h1))\n",
    "elements.append(Paragraph(f'The top film in our database, accorindg to TMDB reviews is <strong>{df_films.head(1).index[0]}</strong>', style=style_normal))\n",
    "elements.append(br)\n",
    "\n",
    "elements.append(Paragraph('Top 10 Films', style=style_h1))\n",
    "elements.append(Paragraph('Here are the top 10 films in our database, according to the sentiment found in the TMDb reviews, ranging from 0 (negative) to 5 (positive).', style=style_normal))\n",
    "elements.append(Table(top_10_films.copy().reset_index().to_numpy().tolist(), style=style_grid))\n",
    "elements.append(br)\n",
    "\n",
    "elements.append(Paragraph('Worst 10 Films', style=style_h1))\n",
    "elements.append(Paragraph('Here are the worst 10 films in our database, according to the sentiment found in the TMDb reviews, ranging from 0 (negative) to 5 (positive).', style=style_normal))\n",
    "elements.append(Table(worst_10_films.copy().reset_index().to_numpy().tolist(), style=style_grid))\n",
    "elements.append(br)\n",
    "\n",
    "elements.append(Paragraph('Review Sentiment Distibution', style=style_h1))\n",
    "elements.append(Image(film_review_distro_path))\n",
    "elements.append(br)\n",
    "\n",
    "elements.append(Paragraph('Top 10 Actors/Actresses in Best Reviewed Films', style=style_h1))\n",
    "elements.append(Paragraph('The ranking bellow is of actors that worked in films with positive reviews. Reviews are not made directly to actors, but to their films', style=style_normal))\n",
    "elements.append(Table(top_10_cast.copy().reset_index().to_numpy().tolist(), style=style_grid))\n",
    "elements.append(br)\n",
    "\n",
    "elements.append(Paragraph('IMDb Average Voting vs TMDb Sentiment Reviews', style=style_h1))\n",
    "elements.append(Image(year_review_distro_path))\n",
    "\n",
    "doc.build(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
