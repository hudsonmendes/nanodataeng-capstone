{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG - Movie Review Sentiment Classifier Trainer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The present document shows how the model must be created, trained, and evaluates how well it performs on some anedoctal test scenarios. Once the training logic is ready, the code here presente must become an Airflow Operator that will then be referenced in the Model Training DAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:43:35.326483Z",
     "start_time": "2020-07-28T20:43:35.321432Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_len    = 500\n",
    "vocab_size = 10000\n",
    "batch_size = 50\n",
    "epochs     = 5\n",
    "emb_dims   = 64\n",
    "lstm_units = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:43:35.824807Z",
     "start_time": "2020-07-28T20:43:35.820762Z"
    }
   },
   "outputs": [],
   "source": [
    "imdb_sentiment_path = 'data/raw/imdb-sentiment.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:43:36.155229Z",
     "start_time": "2020-07-28T20:43:36.150166Z"
    }
   },
   "outputs": [],
   "source": [
    "output_model_path = 'model/movie-sentiment-classifier'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:43:59.419755Z",
     "start_time": "2020-07-28T20:43:36.826594Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U numpy\n",
    "!pip install -U pandas\n",
    "!pip install -U tensorflow\n",
    "!pip install -U scikit-learn\n",
    "!pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:44:12.104770Z",
     "start_time": "2020-07-28T20:43:59.433470Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:44:12.686449Z",
     "start_time": "2020-07-28T20:44:12.110062Z"
    }
   },
   "outputs": [],
   "source": [
    "df = None\n",
    "with zipfile.ZipFile(imdb_sentiment_path) as zip_file:\n",
    "    df = pd.read_csv(\n",
    "        zip_file.open('train.csv'),\n",
    "        header=0,\n",
    "        error_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:44:12.697673Z",
     "start_time": "2020-07-28T20:44:12.690756Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(texts, vocab_size):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=vocab_size,\n",
    "        filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "        lower=True,\n",
    "        split=' ',\n",
    "        oov_token='<oov>',\n",
    "        document_count=0)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:44:18.286597Z",
     "start_time": "2020-07-28T20:44:12.701221Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer(df.text, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:44:18.305221Z",
     "start_time": "2020-07-28T20:44:18.289719Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    tokenizer.num_words,\n",
    "    tokenizer.word_index['something'],\n",
    "    tokenizer.index_word[139])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:44:18.434477Z",
     "start_time": "2020-07-28T20:44:18.316334Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(tokenizer.word_index, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.936562Z",
     "start_time": "2020-07-28T20:41:47.782Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_input_and_target(df, tokenizer):\n",
    "    x = tokenizer.texts_to_sequences(df.text)\n",
    "    y = list(df.sentiment)\n",
    "    return x, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.939365Z",
     "start_time": "2020-07-28T20:41:47.785Z"
    }
   },
   "outputs": [],
   "source": [
    "x_raw, y_raw = extract_input_and_target(df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.944560Z",
     "start_time": "2020-07-28T20:41:47.792Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'x_raw.shape: {(len(x_raw), len(x_raw[0]))}')\n",
    "print(f'y_raw.shape: {(len(y_raw),)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.949478Z",
     "start_time": "2020-07-28T20:41:47.796Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_input(x, seq_len):\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        x,\n",
    "        maxlen=seq_len,\n",
    "        dtype='int32',\n",
    "        padding='post',\n",
    "        value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.952071Z",
     "start_time": "2020-07-28T20:41:47.804Z"
    }
   },
   "outputs": [],
   "source": [
    "x_padded = pad_input(x_raw, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.955656Z",
     "start_time": "2020-07-28T20:41:47.809Z"
    }
   },
   "outputs": [],
   "source": [
    "x_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.959121Z",
     "start_time": "2020-07-28T20:41:47.813Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(x_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.962932Z",
     "start_time": "2020-07-28T20:41:47.817Z"
    }
   },
   "outputs": [],
   "source": [
    "def categorise_target(y):\n",
    "    y = np.array(y)\n",
    "    return y.reshape(y.shape[0], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.965418Z",
     "start_time": "2020-07-28T20:41:47.820Z"
    }
   },
   "outputs": [],
   "source": [
    "y_categorical = categorise_target(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.968278Z",
     "start_time": "2020-07-28T20:41:47.823Z"
    }
   },
   "outputs": [],
   "source": [
    "y_categorical.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.971823Z",
     "start_time": "2020-07-28T20:41:47.826Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.974050Z",
     "start_time": "2020-07-28T20:41:47.828Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_padded, y_categorical, train_size=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.976704Z",
     "start_time": "2020-07-28T20:41:47.832Z"
    }
   },
   "outputs": [],
   "source": [
    "[ x_train.shape, y_train.shape, x_valid.shape, y_valid.shape]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.979227Z",
     "start_time": "2020-07-28T20:41:47.836Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size, seq_len, emb_dims, lstm_units):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=emb_dims, input_length=seq_len, mask_zero=True),\n",
    "        tf.keras.layers.LSTM(lstm_units, dropout=0.5, recurrent_dropout=0.5),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.982896Z",
     "start_time": "2020-07-28T20:41:47.839Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "    vocab_size=vocab_size,\n",
    "    seq_len=seq_len,\n",
    "    emb_dims=emb_dims,\n",
    "    lstm_units=lstm_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.985014Z",
     "start_time": "2020-07-28T20:41:47.841Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train, valid, batch_size=32, epochs=3):\n",
    "    return model.fit(\n",
    "        x=train[0], y=train[1],\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=valid,\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.987511Z",
     "start_time": "2020-07-28T20:41:47.844Z"
    }
   },
   "outputs": [],
   "source": [
    "train_result = train_model(\n",
    "    model,\n",
    "    train=(x_train, y_train),\n",
    "    valid=(x_valid, y_valid),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.990432Z",
     "start_time": "2020-07-28T20:41:47.853Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_metric(history, metric):\n",
    "    train = history[metric]\n",
    "    valid = history[f'val_{metric}']\n",
    "    epochs = range(1, len(train) + 1)\n",
    "    plt.plot(epochs, train, f'b', label=f'{metric} (train)')\n",
    "    plt.plot(epochs, valid, f'g', label=f'{metric} (valid)')\n",
    "    plt.title('{metric}: training vs validation')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.xlabel(metric)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.992880Z",
     "start_time": "2020-07-28T20:41:47.864Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_metric(train_result.history, 'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.996371Z",
     "start_time": "2020-07-28T20:41:47.867Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_metric(train_result.history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:42:24.998710Z",
     "start_time": "2020-07-28T20:41:47.871Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(output_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T20:49:47.948160Z",
     "start_time": "2020-07-28T20:49:47.294722Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{output_model_path}/assets/tokenizer.json', 'w+', encoding='utf-8') as file:\n",
    "    file.write(tokenizer.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM**\n",
    "```\n",
    "seq_len    = 500\n",
    "vocab_size = 10000\n",
    "batch_size = 50\n",
    "epochs     = 5\n",
    "emb_dims   = 64\n",
    "lstm_units = 128\n",
    "\n",
    "Epoch 1/5 - loss: 0.4595 - acc: 0.7863 - val_loss: 0.2429 - val_acc: 0.9120\n",
    "Epoch 2/5 - loss: 0.3095 - acc: 0.8804 - val_loss: 0.2876 - val_acc: 0.8920\n",
    "Epoch 3/5 - loss: 0.2568 - acc: 0.9016 - val_loss: 0.4429 - val_acc: 0.8360\n",
    "Epoch 4/5 - loss: 0.2358 - acc: 0.9108 - val_loss: 0.2617 - val_acc: 0.9120\n",
    "Epoch 5/5 - loss: 0.2121 - acc: 0.9207 - val_loss: 0.2542 - val_acc: 0.9120\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BiLSTM**\n",
    "```\n",
    "seq_len    = 500\n",
    "vocab_size = 10000\n",
    "batch_size = 50\n",
    "epochs     = 5\n",
    "emb_dims   = 128\n",
    "lstm_units = 128\n",
    "\n",
    "Epoch 1/5 - loss: 0.4488 - acc: 0.7933 - val_loss: 0.2628 - val_acc: 0.9040\n",
    "Epoch 2/5 - loss: 0.2688 - acc: 0.8933 - val_loss: 0.3313 - val_acc: 0.8960\n",
    "Epoch 3/5 - loss: 0.2201 - acc: 0.9145 - val_loss: 0.2992 - val_acc: 0.8920\n",
    "Epoch 4/5 - loss: 0.1888 - acc: 0.9289 - val_loss: 0.2390 - val_acc: 0.8680\n",
    "Epoch 5/5 - loss: 0.1633 - acc: 0.9374 - val_loss: 0.2607 - val_acc: 0.8640\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
